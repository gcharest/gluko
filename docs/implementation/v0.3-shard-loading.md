# Implementation: v0.3 Shard-Based Dataset Loading

## Overview

This document provides implementation details for v0.3, which implements NDJSON-based dataset sharding with manifest versioning and incremental updates. This enables efficient dataset management without requiring re-download of entire dataset when data hasn't changed. See the [release planning document](../releases/v0.3-shard-loading.md) for goals and context.

## Architecture

### High-Level Flow

```text
User Opens App (First Time)
    ↓
Fetch manifest.json from static host
    ↓
Check IndexedDB for existing manifest version
    ↓
Compare manifest versions/checksums
    ↓
Download only new/changed shards
    ↓
Validate shard checksums
    ↓
Import shards atomically to IndexedDB
    ↓
Update local manifest version
    ↓
Dataset ready for search/calculation

Subsequent Visits:
    ↓
Fetch manifest.json
    ↓
Compare with local manifest
    ↓
If unchanged → Use cached data (zero downloads)
    ↓
If changed → Download only changed shards
```

### Key Components Added in v0.3

1. **Manifest System**: Version tracking and shard coordination
   - `manifest.json` hosted on GitHub Pages
   - Contains shard list with checksums and metadata
   - Version number for cache busting
   - Total dataset size for quota checks

2. **Shard Format**: NDJSON files for incremental loading
   - Uncompressed `.ndjson` files (GitHub Pages constraint)
   - Target size: 2-3 MB per shard
   - Each line is a valid JSON object (NutrientRecord)
   - Shards organized by food group or alphabetically

3. **Shard Loader**: Download and validation logic
   - `useShardLoader` composable
   - Checksums validation (SHA-256)
   - Progress tracking per shard
   - Resumability after interruptions
   - Storage quota checking before download

4. **IndexedDB Schema Updates**:
   - New `shardMetadata` store for tracking loaded shards
   - New `manifestVersion` store for version tracking
   - Enhanced `nutrientsFile` store indexes for efficient queries

5. **ETL Pipeline**: Build-time dataset processing
   - Node.js script to split dataset into shards
   - Generate manifest.json with checksums
   - Deterministic sharding algorithm
   - Outputs to `public/data/` directory

6. **UI Components**: Progress and storage management
   - Shard download progress indicator
   - Storage quota display in settings
   - Dataset update notifications
   - Error recovery UI

## API Specifications

### Manifest Format

#### File: `public/data/manifest.json`

```typescript
interface ManifestFile {
  version: string;              // Semantic version (e.g., "0.3.0")
  generatedAt: string;          // ISO timestamp
  totalRecords: number;         // Total food records across all shards
  totalSizeBytes: number;       // Uncompressed size of all shards
  shards: ShardDescriptor[];    // Array of shard metadata
}

interface ShardDescriptor {
  id: string;                   // Unique shard identifier (e.g., "shard-001")
  filename: string;             // File name (e.g., "nutrients-001.ndjson")
  checksum: string;             // SHA-256 hash of file contents
  sizeBytes: number;            // Uncompressed file size
  recordCount: number;          // Number of records in shard
  recordRange?: {               // Optional range metadata
    start: string;              // First food ID or description
    end: string;                // Last food ID or description
  };
}
```

#### Example Manifest

```json
{
  "version": "0.3.0",
  "generatedAt": "2025-01-15T10:30:00.000Z",
  "totalRecords": 7125,
  "totalSizeBytes": 15728640,
  "shards": [
    {
      "id": "shard-001",
      "filename": "nutrients-001.ndjson",
      "checksum": "a1b2c3d4e5f6...",
      "sizeBytes": 2621440,
      "recordCount": 1187,
      "recordRange": {
        "start": "Abiyuch, raw",
        "end": "Beef, composite cuts"
      }
    },
    {
      "id": "shard-002",
      "filename": "nutrients-002.ndjson",
      "checksum": "f6e5d4c3b2a1...",
      "sizeBytes": 2883584,
      "recordCount": 1279,
      "recordRange": {
        "start": "Beef, ground",
        "end": "Cheese, cheddar"
      }
    }
  ]
}
```

### Shard File Format

#### File: `public/data/nutrients-001.ndjson`

Each line is a complete JSON object:

```ndjson
{"id":"1001","FoodDescription":"Butter, salted","FoodDescriptionF":"Beurre, salé","FoodGroup":"Dairy","measure":"tbsp","measureF":"c. à table","nutrient_203":0.85,"nutrient_204":81.11,"nutrient_205":0.06,"nutrient_291":0,"FctGluc":1.0}
{"id":"1002","FoodDescription":"Butter, unsalted","FoodDescriptionF":"Beurre, non salé","FoodGroup":"Dairy","measure":"tbsp","measureF":"c. à table","nutrient_203":0.85,"nutrient_204":81.11,"nutrient_205":0.06,"nutrient_291":0,"FctGluc":1.0}
```

**Format Requirements**:
- One JSON object per line (NDJSON standard)
- No trailing commas
- UTF-8 encoding
- Unix line endings (LF)
- No blank lines

### IndexedDB Schema Updates

#### New Store: `shardMetadata`

```typescript
interface ShardMetadata {
  id: string;                   // Shard ID (primary key)
  filename: string;             // Shard filename
  checksum: string;             // Expected checksum
  loadedAt: number;             // Timestamp when loaded
  recordCount: number;          // Number of records imported
  status: 'pending' | 'loaded' | 'error';
  errorMessage?: string;        // Error details if status is 'error'
}

// No indexes needed (lookup by primary key only)
```

#### New Store: `manifestVersion`

```typescript
interface ManifestVersion {
  id: 'current';                // Singleton key
  version: string;              // Current manifest version
  updatedAt: number;            // Last update timestamp
  totalRecords: number;         // Expected total records
  loadedShards: number;         // Number of shards successfully loaded
}

// No indexes needed (singleton)
```

#### Updated Store: `nutrientsFile`

No schema changes, but enhanced indexes for performance:

```typescript
// Existing indexes:
// - Primary key: id (FOOD_ID)

// NEW indexes for v0.3:
// - "by-food-group": FoodGroup
// - "by-description": FoodDescription
// - "by-description-fr": FoodDescriptionF
```

### Core Composables/Functions

#### `useShardLoader()`

```typescript
export function useShardLoader() {
  interface LoadProgress {
    currentShard: number;
    totalShards: number;
    currentShardProgress: number;  // 0-100
    status: 'idle' | 'fetching-manifest' | 'downloading' | 'importing' | 'complete' | 'error';
    error?: string;
  }

  const progress = ref<LoadProgress>({
    currentShard: 0,
    totalShards: 0,
    currentShardProgress: 0,
    status: 'idle'
  })

  // Fetch and parse manifest from remote
  async function fetchManifest(): Promise<ManifestFile>

  // Compare remote manifest with local version
  async function getChangedShards(remoteManifest: ManifestFile): Promise<ShardDescriptor[]>

  // Download single shard with progress tracking
  async function downloadShard(shard: ShardDescriptor): Promise<string>

  // Validate shard checksum
  async function validateChecksum(content: string, expectedChecksum: string): Promise<boolean>

  // Parse NDJSON content into records
  function parseNDJSON(content: string): NutrientRecord[]

  // Import shard atomically to IndexedDB
  async function importShard(shard: ShardDescriptor, records: NutrientRecord[]): Promise<void>

  // Orchestrate full update process
  async function updateDataset(): Promise<void>

  // Check storage quota before download
  async function checkStorageQuota(requiredBytes: number): Promise<{ available: number, sufficient: boolean }>

  return {
    progress,
    fetchManifest,
    getChangedShards,
    downloadShard,
    validateChecksum,
    parseNDJSON,
    importShard,
    updateDataset,
    checkStorageQuota
  }
}
```

#### `useStorageQuota()`

```typescript
export function useStorageQuota() {
  interface QuotaInfo {
    quota: number;              // Total available storage (bytes)
    usage: number;              // Current usage (bytes)
    available: number;          // Available space (bytes)
    percentUsed: number;        // Usage percentage (0-100)
  }

  const quotaInfo = ref<QuotaInfo | null>(null)
  const isLowStorage = computed(() => quotaInfo.value && quotaInfo.value.percentUsed > 80)
  const isCriticalStorage = computed(() => quotaInfo.value && quotaInfo.value.percentUsed > 90)

  // Fetch current storage quota
  async function updateQuotaInfo(): Promise<void>

  // Check if enough space for operation
  async function checkAvailableSpace(requiredBytes: number): Promise<boolean>

  // Show warning if storage is low
  function showStorageWarning(): void

  // Offer cleanup options
  async function cleanupStorage(): Promise<void>

  return {
    quotaInfo,
    isLowStorage,
    isCriticalStorage,
    updateQuotaInfo,
    checkAvailableSpace,
    showStorageWarning,
    cleanupStorage
  }
}
```

#### Enhanced `useIndexedDB()`

Add new methods for shard management:

```typescript
// Add to existing useIndexedDB composable

// Shard metadata operations
async function saveShardMetadata(metadata: ShardMetadata): Promise<void>
async function getShardMetadata(shardId: string): Promise<ShardMetadata | null>
async function getAllShardMetadata(): Promise<ShardMetadata[]>
async function deleteShardMetadata(shardId: string): Promise<void>

// Manifest version operations
async function saveManifestVersion(version: ManifestVersion): Promise<void>
async function getManifestVersion(): Promise<ManifestVersion | null>

// Bulk import with transaction safety
async function importNutrientRecords(records: NutrientRecord[]): Promise<void>

// Database upgrade handler
function upgradeDatabase(db: IDBDatabase, oldVersion: number, newVersion: number): void
```

## Implementation Details

### 1. ETL Pipeline (Build-Time)

#### File: `scripts/generate-shards.js`

```javascript
import fs from 'fs'
import path from 'path'
import crypto from 'crypto'

const SHARD_TARGET_SIZE = 2.5 * 1024 * 1024  // 2.5 MB target
const INPUT_FILE = './data/canadian-nutrient-file.json'
const OUTPUT_DIR = './public/data'

async function generateShards() {
  console.log('Loading dataset...')
  const dataset = JSON.parse(fs.readFileSync(INPUT_FILE, 'utf8'))

  console.log(`Total records: ${dataset.length}`)

  // Sort by FoodDescription for deterministic sharding
  dataset.sort((a, b) => a.FoodDescription.localeCompare(b.FoodDescription))

  const shards = []
  let currentShard = []
  let currentSize = 0
  let shardIndex = 1

  for (const record of dataset) {
    const recordSize = JSON.stringify(record).length + 1  // +1 for newline

    if (currentSize + recordSize > SHARD_TARGET_SIZE && currentShard.length > 0) {
      // Write current shard
      const shardInfo = await writeShard(currentShard, shardIndex)
      shards.push(shardInfo)

      // Start new shard
      currentShard = [record]
      currentSize = recordSize
      shardIndex++
    } else {
      currentShard.push(record)
      currentSize += recordSize
    }
  }

  // Write final shard
  if (currentShard.length > 0) {
    const shardInfo = await writeShard(currentShard, shardIndex)
    shards.push(shardInfo)
  }

  // Generate manifest
  const manifest = {
    version: process.env.npm_package_version || '0.3.0',
    generatedAt: new Date().toISOString(),
    totalRecords: dataset.length,
    totalSizeBytes: shards.reduce((sum, s) => sum + s.sizeBytes, 0),
    shards
  }

  fs.writeFileSync(
    path.join(OUTPUT_DIR, 'manifest.json'),
    JSON.stringify(manifest, null, 2)
  )

  console.log(`Generated ${shards.length} shards`)
  console.log(`Total size: ${(manifest.totalSizeBytes / 1024 / 1024).toFixed(2)} MB`)
}

async function writeShard(records, index) {
  const filename = `nutrients-${String(index).padStart(3, '0')}.ndjson`
  const filepath = path.join(OUTPUT_DIR, filename)

  // Convert to NDJSON
  const ndjsonContent = records.map(r => JSON.stringify(r)).join('\n')

  // Write file
  fs.writeFileSync(filepath, ndjsonContent, 'utf8')

  // Calculate checksum
  const checksum = crypto
    .createHash('sha256')
    .update(ndjsonContent)
    .digest('hex')

  // Calculate size
  const sizeBytes = Buffer.byteLength(ndjsonContent, 'utf8')

  return {
    id: `shard-${String(index).padStart(3, '0')}`,
    filename,
    checksum,
    sizeBytes,
    recordCount: records.length,
    recordRange: {
      start: records[0].FoodDescription,
      end: records[records.length - 1].FoodDescription
    }
  }
}

generateShards().catch(console.error)
```

#### Integration with Build Process

Update `package.json`:

```json
{
  "scripts": {
    "generate-shards": "node scripts/generate-shards.js",
    "prebuild": "npm run generate-shards",
    "build": "vite build"
  }
}
```

### 2. Shard Loader Implementation

#### File: `src/composables/useShardLoader.ts`

```typescript
import { ref, computed } from 'vue'
import { useIndexedDB } from './useIndexedDB'
import type { ManifestFile, ShardDescriptor, NutrientRecord } from '@/types'

const MANIFEST_URL = '/gluko/data/manifest.json'
const SHARD_BASE_URL = '/gluko/data/'

export function useShardLoader() {
  const db = useIndexedDB()

  const progress = ref({
    currentShard: 0,
    totalShards: 0,
    currentShardProgress: 0,
    status: 'idle' as const
  })

  async function fetchManifest(): Promise<ManifestFile> {
    progress.value.status = 'fetching-manifest'

    try {
      const response = await fetch(MANIFEST_URL, {
        cache: 'no-cache',  // Always fetch latest manifest
        headers: {
          'Accept': 'application/json'
        }
      })

      if (!response.ok) {
        throw new Error(`Failed to fetch manifest: ${response.statusText}`)
      }

      return await response.json()
    } catch (error) {
      progress.value.status = 'error'
      progress.value.error = error instanceof Error ? error.message : 'Unknown error'
      throw error
    }
  }

  async function getChangedShards(remoteManifest: ManifestFile): Promise<ShardDescriptor[]> {
    const localVersion = await db.getManifestVersion()

    // First install - download all shards
    if (!localVersion) {
      return remoteManifest.shards
    }

    // Version unchanged - no downloads needed
    if (localVersion.version === remoteManifest.version) {
      return []
    }

    // Check which shards have changed
    const changedShards: ShardDescriptor[] = []

    for (const remoteShard of remoteManifest.shards) {
      const localShard = await db.getShardMetadata(remoteShard.id)

      // New shard or checksum changed
      if (!localShard || localShard.checksum !== remoteShard.checksum) {
        changedShards.push(remoteShard)
      }
    }

    return changedShards
  }

  async function downloadShard(shard: ShardDescriptor): Promise<string> {
    const url = `${SHARD_BASE_URL}${shard.filename}`

    try {
      const response = await fetch(url, {
        cache: 'no-cache'
      })

      if (!response.ok) {
        throw new Error(`Failed to download shard ${shard.id}: ${response.statusText}`)
      }

      // Read with progress tracking
      const reader = response.body?.getReader()
      if (!reader) {
        throw new Error('Response body is not readable')
      }

      const contentLength = parseInt(response.headers.get('Content-Length') || '0')
      let receivedLength = 0
      const chunks: Uint8Array[] = []

      while (true) {
        const { done, value } = await reader.read()

        if (done) break

        chunks.push(value)
        receivedLength += value.length

        if (contentLength > 0) {
          progress.value.currentShardProgress = Math.round(
            (receivedLength / contentLength) * 100
          )
        }
      }

      // Combine chunks
      const allChunks = new Uint8Array(receivedLength)
      let position = 0
      for (const chunk of chunks) {
        allChunks.set(chunk, position)
        position += chunk.length
      }

      const content = new TextDecoder('utf-8').decode(allChunks)
      return content
    } catch (error) {
      throw new Error(
        `Download failed for ${shard.filename}: ${
          error instanceof Error ? error.message : 'Unknown error'
        }`
      )
    }
  }

  async function validateChecksum(content: string, expectedChecksum: string): Promise<boolean> {
    // Use SubtleCrypto API for SHA-256
    const encoder = new TextEncoder()
    const data = encoder.encode(content)
    const hashBuffer = await crypto.subtle.digest('SHA-256', data)

    // Convert to hex string
    const hashArray = Array.from(new Uint8Array(hashBuffer))
    const hashHex = hashArray.map(b => b.toString(16).padStart(2, '0')).join('')

    return hashHex === expectedChecksum
  }

  function parseNDJSON(content: string): NutrientRecord[] {
    const lines = content.split('\n').filter(line => line.trim().length > 0)
    const records: NutrientRecord[] = []

    for (let i = 0; i < lines.length; i++) {
      try {
        const record = JSON.parse(lines[i])

        // Validate required fields
        if (!record.id || !record.FoodDescription) {
          console.warn(`Invalid record at line ${i + 1}, skipping`)
          continue
        }

        records.push(record)
      } catch (error) {
        console.error(`Failed to parse line ${i + 1}:`, error)
        throw new Error(`Invalid NDJSON at line ${i + 1}`)
      }
    }

    return records
  }

  async function importShard(
    shard: ShardDescriptor,
    records: NutrientRecord[]
  ): Promise<void> {
    try {
      // Import records atomically
      await db.importNutrientRecords(records)

      // Save shard metadata
      await db.saveShardMetadata({
        id: shard.id,
        filename: shard.filename,
        checksum: shard.checksum,
        loadedAt: Date.now(),
        recordCount: records.length,
        status: 'loaded'
      })
    } catch (error) {
      // Save error state
      await db.saveShardMetadata({
        id: shard.id,
        filename: shard.filename,
        checksum: shard.checksum,
        loadedAt: Date.now(),
        recordCount: 0,
        status: 'error',
        errorMessage: error instanceof Error ? error.message : 'Unknown error'
      })

      throw error
    }
  }

  async function checkStorageQuota(requiredBytes: number): Promise<{
    available: number
    sufficient: boolean
  }> {
    if (!navigator.storage?.estimate) {
      // API not available, assume sufficient
      return { available: Infinity, sufficient: true }
    }

    const quota = await navigator.storage.estimate()
    const available = (quota.quota || 0) - (quota.usage || 0)
    const percentUsed = Math.round(((quota.usage || 0) / (quota.quota || 1)) * 100)

    if (percentUsed > 90) {
      console.warn(`Storage ${percentUsed}% full`)
    }

    return {
      available,
      sufficient: available >= requiredBytes
    }
  }

  async function updateDataset(): Promise<void> {
    progress.value.status = 'fetching-manifest'

    try {
      // Fetch manifest
      const manifest = await fetchManifest()

      // Check storage quota
      const quotaCheck = await checkStorageQuota(manifest.totalSizeBytes)
      if (!quotaCheck.sufficient) {
        throw new Error(
          `Insufficient storage. Required: ${(manifest.totalSizeBytes / 1024 / 1024).toFixed(2)} MB, ` +
          `Available: ${(quotaCheck.available / 1024 / 1024).toFixed(2)} MB`
        )
      }

      // Get shards that need updating
      const shardsToLoad = await getChangedShards(manifest)

      if (shardsToLoad.length === 0) {
        console.log('Dataset is up to date')
        progress.value.status = 'complete'
        return
      }

      console.log(`Loading ${shardsToLoad.length} shard(s)`)
      progress.value.totalShards = shardsToLoad.length
      progress.value.status = 'downloading'

      // Download and import each shard
      for (let i = 0; i < shardsToLoad.length; i++) {
        const shard = shardsToLoad[i]
        progress.value.currentShard = i + 1
        progress.value.currentShardProgress = 0

        console.log(`Downloading ${shard.filename}...`)
        const content = await downloadShard(shard)

        console.log(`Validating checksum for ${shard.filename}...`)
        const isValid = await validateChecksum(content, shard.checksum)
        if (!isValid) {
          throw new Error(`Checksum validation failed for ${shard.filename}`)
        }

        progress.value.status = 'importing'
        console.log(`Parsing ${shard.filename}...`)
        const records = parseNDJSON(content)

        console.log(`Importing ${records.length} records from ${shard.filename}...`)
        await importShard(shard, records)

        progress.value.status = 'downloading'
      }

      // Update manifest version
      await db.saveManifestVersion({
        id: 'current',
        version: manifest.version,
        updatedAt: Date.now(),
        totalRecords: manifest.totalRecords,
        loadedShards: shardsToLoad.length
      })

      progress.value.status = 'complete'
      console.log('Dataset update complete')
    } catch (error) {
      progress.value.status = 'error'
      progress.value.error = error instanceof Error ? error.message : 'Unknown error'
      throw error
    }
  }

  return {
    progress,
    fetchManifest,
    getChangedShards,
    downloadShard,
    validateChecksum,
    parseNDJSON,
    importShard,
    updateDataset,
    checkStorageQuota
  }
}
```

### 3. IndexedDB Schema Upgrade

#### File: `src/composables/useIndexedDB.ts` (additions)

```typescript
const DB_NAME = 'gluko-db'
const DB_VERSION = 3  // Increment from v0.2

function upgradeDatabase(db: IDBDatabase, oldVersion: number, newVersion: number | null) {
  console.log(`Upgrading database from version ${oldVersion} to ${newVersion}`)

  // v0.1 schema (existing)
  if (oldVersion < 1) {
    // Create initial stores
    // ... existing v0.1 schema creation
  }

  // v0.2 schema (existing)
  if (oldVersion < 2) {
    // Add indexes
    // ... existing v0.2 schema updates
  }

  // v0.3 schema (NEW)
  if (oldVersion < 3) {
    // Create shardMetadata store
    const shardStore = db.createObjectStore('shardMetadata', { keyPath: 'id' })
    console.log('Created shardMetadata store')

    // Create manifestVersion store
    const manifestStore = db.createObjectStore('manifestVersion', { keyPath: 'id' })
    console.log('Created manifestVersion store')

    // Add indexes to nutrientsFile store
    const nutrientsStore = transaction.objectStore('nutrientsFile')
    if (!nutrientsStore.indexNames.contains('by-food-group')) {
      nutrientsStore.createIndex('by-food-group', 'FoodGroup', { unique: false })
      console.log('Added by-food-group index')
    }
    if (!nutrientsStore.indexNames.contains('by-description')) {
      nutrientsStore.createIndex('by-description', 'FoodDescription', { unique: false })
      console.log('Added by-description index')
    }
    if (!nutrientsStore.indexNames.contains('by-description-fr')) {
      nutrientsStore.createIndex('by-description-fr', 'FoodDescriptionF', { unique: false })
      console.log('Added by-description-fr index')
    }
  }
}

// Add new methods for shard management

async function saveShardMetadata(metadata: ShardMetadata): Promise<void> {
  const db = await openDB()
  return new Promise((resolve, reject) => {
    const transaction = db.transaction(['shardMetadata'], 'readwrite')
    const store = transaction.objectStore('shardMetadata')

    const request = store.put(metadata)
    request.onsuccess = () => resolve()
    request.onerror = () => reject(request.error)
  })
}

async function getShardMetadata(shardId: string): Promise<ShardMetadata | null> {
  const db = await openDB()
  return new Promise((resolve, reject) => {
    const transaction = db.transaction(['shardMetadata'], 'readonly')
    const store = transaction.objectStore('shardMetadata')

    const request = store.get(shardId)
    request.onsuccess = () => resolve(request.result || null)
    request.onerror = () => reject(request.error)
  })
}

async function getAllShardMetadata(): Promise<ShardMetadata[]> {
  const db = await openDB()
  return new Promise((resolve, reject) => {
    const transaction = db.transaction(['shardMetadata'], 'readonly')
    const store = transaction.objectStore('shardMetadata')

    const request = store.getAll()
    request.onsuccess = () => resolve(request.result)
    request.onerror = () => reject(request.error)
  })
}

async function deleteShardMetadata(shardId: string): Promise<void> {
  const db = await openDB()
  return new Promise((resolve, reject) => {
    const transaction = db.transaction(['shardMetadata'], 'readwrite')
    const store = transaction.objectStore('shardMetadata')

    const request = store.delete(shardId)
    request.onsuccess = () => resolve()
    request.onerror = () => reject(request.error)
  })
}

async function saveManifestVersion(version: ManifestVersion): Promise<void> {
  const db = await openDB()
  return new Promise((resolve, reject) => {
    const transaction = db.transaction(['manifestVersion'], 'readwrite')
    const store = transaction.objectStore('manifestVersion')

    const request = store.put(version)
    request.onsuccess = () => resolve()
    request.onerror = () => reject(request.error)
  })
}

async function getManifestVersion(): Promise<ManifestVersion | null> {
  const db = await openDB()
  return new Promise((resolve, reject) => {
    const transaction = db.transaction(['manifestVersion'], 'readonly')
    const store = transaction.objectStore('manifestVersion')

    const request = store.get('current')
    request.onsuccess = () => resolve(request.result || null)
    request.onerror = () => reject(request.error)
  })
}

async function importNutrientRecords(records: NutrientRecord[]): Promise<void> {
  const db = await openDB()

  return new Promise((resolve, reject) => {
    const transaction = db.transaction(['nutrientsFile'], 'readwrite')
    const store = transaction.objectStore('nutrientsFile')

    // Add all records in single transaction (atomic)
    for (const record of records) {
      store.put(record)  // Use put to update existing records
    }

    transaction.oncomplete = () => resolve()
    transaction.onerror = () => reject(transaction.error)
    transaction.onabort = () => reject(new Error('Transaction aborted'))
  })
}
```

### 4. Storage Quota Management

#### File: `src/composables/useStorageQuota.ts`

```typescript
import { ref, computed } from 'vue'

export interface QuotaInfo {
  quota: number
  usage: number
  available: number
  percentUsed: number
}

export function useStorageQuota() {
  const quotaInfo = ref<QuotaInfo | null>(null)

  const isLowStorage = computed(() =>
    quotaInfo.value && quotaInfo.value.percentUsed > 80
  )

  const isCriticalStorage = computed(() =>
    quotaInfo.value && quotaInfo.value.percentUsed > 90
  )

  async function updateQuotaInfo(): Promise<void> {
    if (!navigator.storage?.estimate) {
      console.warn('Storage API not available')
      return
    }

    try {
      const estimate = await navigator.storage.estimate()

      quotaInfo.value = {
        quota: estimate.quota || 0,
        usage: estimate.usage || 0,
        available: (estimate.quota || 0) - (estimate.usage || 0),
        percentUsed: Math.round(((estimate.usage || 0) / (estimate.quota || 1)) * 100)
      }
    } catch (error) {
      console.error('Failed to get storage estimate:', error)
    }
  }

  async function checkAvailableSpace(requiredBytes: number): Promise<boolean> {
    await updateQuotaInfo()

    if (!quotaInfo.value) {
      // Assume sufficient if API not available
      return true
    }

    return quotaInfo.value.available >= requiredBytes
  }

  function showStorageWarning(): void {
    if (!quotaInfo.value) return

    if (isCriticalStorage.value) {
      alert(
        `Storage is ${quotaInfo.value.percentUsed}% full. ` +
        `Please free up space before downloading dataset.`
      )
    } else if (isLowStorage.value) {
      console.warn(
        `Storage is ${quotaInfo.value.percentUsed}% full. ` +
        `Consider freeing up space.`
      )
    }
  }

  async function cleanupStorage(): Promise<void> {
    // Placeholder for future cleanup implementation
    // Options:
    // 1. Delete meal history older than N months
    // 2. Clear cached search results
    // 3. Export data and clear local storage
    console.log('Cleanup storage - not yet implemented')
  }

  // Initialize on creation
  updateQuotaInfo()

  return {
    quotaInfo,
    isLowStorage,
    isCriticalStorage,
    updateQuotaInfo,
    checkAvailableSpace,
    showStorageWarning,
    cleanupStorage
  }
}
```

### 5. UI Components

#### File: `src/components/DatasetUpdateProgress.vue`

```vue
<template>
  <div v-if="showProgress" class="dataset-update-progress">
    <div class="card">
      <div class="card-body">
        <h5 class="card-title">
          {{ $t('dataset.updating') }}
        </h5>

        <div v-if="progress.status === 'fetching-manifest'" class="text-center">
          <div class="spinner-border text-primary" role="status">
            <span class="visually-hidden">{{ $t('common.loading') }}</span>
          </div>
          <p class="mt-2">{{ $t('dataset.fetchingManifest') }}</p>
        </div>

        <div v-else-if="progress.status === 'downloading' || progress.status === 'importing'">
          <p class="mb-2">
            {{ $t('dataset.shard') }} {{ progress.currentShard }} / {{ progress.totalShards }}
          </p>

          <div class="progress mb-3" style="height: 25px;">
            <div
              class="progress-bar progress-bar-striped progress-bar-animated"
              role="progressbar"
              :style="{ width: `${progress.currentShardProgress}%` }"
              :aria-valuenow="progress.currentShardProgress"
              aria-valuemin="0"
              aria-valuemax="100"
            >
              {{ progress.currentShardProgress }}%
            </div>
          </div>

          <small class="text-muted">
            {{ progress.status === 'downloading'
              ? $t('dataset.downloading')
              : $t('dataset.importing') }}
          </small>
        </div>

        <div v-else-if="progress.status === 'complete'" class="text-success">
          <i class="bi bi-check-circle-fill"></i>
          {{ $t('dataset.updateComplete') }}
        </div>

        <div v-else-if="progress.status === 'error'" class="text-danger">
          <i class="bi bi-exclamation-triangle-fill"></i>
          {{ $t('dataset.updateFailed') }}: {{ progress.error }}

          <button class="btn btn-sm btn-primary mt-2" @click="retry">
            {{ $t('common.retry') }}
          </button>
        </div>
      </div>
    </div>
  </div>
</template>

<script setup lang="ts">
import { computed } from 'vue'
import { useShardLoader } from '@/composables/useShardLoader'

const { progress, updateDataset } = useShardLoader()

const showProgress = computed(() => progress.value.status !== 'idle')

async function retry() {
  await updateDataset()
}
</script>

<style scoped>
.dataset-update-progress {
  position: fixed;
  bottom: 20px;
  right: 20px;
  width: 350px;
  z-index: 1050;
  box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
}
</style>
```

#### File: `src/components/StorageQuotaDisplay.vue`

```vue
<template>
  <div v-if="quotaInfo" class="storage-quota">
    <h6>{{ $t('settings.storageUsage') }}</h6>

    <div class="progress mb-2" style="height: 20px;">
      <div
        class="progress-bar"
        :class="{
          'bg-success': quotaInfo.percentUsed < 60,
          'bg-warning': quotaInfo.percentUsed >= 60 && quotaInfo.percentUsed < 80,
          'bg-danger': quotaInfo.percentUsed >= 80
        }"
        role="progressbar"
        :style="{ width: `${quotaInfo.percentUsed}%` }"
        :aria-valuenow="quotaInfo.percentUsed"
        aria-valuemin="0"
        aria-valuemax="100"
      >
        {{ quotaInfo.percentUsed }}%
      </div>
    </div>

    <div class="d-flex justify-content-between">
      <small class="text-muted">
        {{ formatBytes(quotaInfo.usage) }} / {{ formatBytes(quotaInfo.quota) }}
      </small>
      <small class="text-muted">
        {{ formatBytes(quotaInfo.available) }} {{ $t('settings.available') }}
      </small>
    </div>

    <div v-if="isLowStorage" class="alert alert-warning mt-2" role="alert">
      <i class="bi bi-exclamation-triangle"></i>
      {{ $t('settings.lowStorageWarning') }}
    </div>

    <div v-if="isCriticalStorage" class="alert alert-danger mt-2" role="alert">
      <i class="bi bi-exclamation-circle"></i>
      {{ $t('settings.criticalStorageWarning') }}

      <button class="btn btn-sm btn-danger mt-2" @click="cleanupStorage">
        {{ $t('settings.freeUpSpace') }}
      </button>
    </div>
  </div>
</template>

<script setup lang="ts">
import { onMounted } from 'vue'
import { useStorageQuota } from '@/composables/useStorageQuota'

const {
  quotaInfo,
  isLowStorage,
  isCriticalStorage,
  updateQuotaInfo,
  cleanupStorage
} = useStorageQuota()

onMounted(() => {
  updateQuotaInfo()
})

function formatBytes(bytes: number): string {
  if (bytes === 0) return '0 B'

  const k = 1024
  const sizes = ['B', 'KB', 'MB', 'GB']
  const i = Math.floor(Math.log(bytes) / Math.log(k))

  return `${(bytes / Math.pow(k, i)).toFixed(2)} ${sizes[i]}`
}
</script>
```

### 6. Application Integration

#### File: `src/App.vue` (additions)

```vue
<template>
  <div id="app">
    <!-- Existing navigation and views -->

    <!-- NEW: Dataset update progress -->
    <DatasetUpdateProgress />

    <!-- NEW: Dataset update notification -->
    <DatasetUpdateNotification
      v-if="hasUpdate"
      @update="handleDatasetUpdate"
      @dismiss="dismissUpdate"
    />
  </div>
</template>

<script setup lang="ts">
import { ref, onMounted } from 'vue'
import DatasetUpdateProgress from '@/components/DatasetUpdateProgress.vue'
import DatasetUpdateNotification from '@/components/DatasetUpdateNotification.vue'
import { useShardLoader } from '@/composables/useShardLoader'

const { fetchManifest, getChangedShards, updateDataset } = useShardLoader()
const hasUpdate = ref(false)

onMounted(async () => {
  // Check for dataset updates on app load
  try {
    const manifest = await fetchManifest()
    const changedShards = await getChangedShards(manifest)

    if (changedShards.length > 0) {
      hasUpdate.value = true
    }
  } catch (error) {
    console.error('Failed to check for updates:', error)
  }
})

async function handleDatasetUpdate() {
  hasUpdate.value = false
  await updateDataset()
}

function dismissUpdate() {
  hasUpdate.value = false
  // Store dismissal in localStorage to not show again until next version
  localStorage.setItem('dataset-update-dismissed', Date.now().toString())
}
</script>
```

## Testing Strategy

### Unit Tests

#### Store Tests

No new stores in v0.3, but existing stores may need updates for enhanced nutrient loading.

#### Composable Tests

**File**: `src/composables/__tests__/useShardLoader.spec.ts`

```typescript
import { describe, it, expect, beforeEach, vi } from 'vitest'
import { useShardLoader } from '../useShardLoader'

describe('useShardLoader', () => {
  beforeEach(() => {
    // Reset fetch mocks
    global.fetch = vi.fn()
  })

  it('should fetch manifest successfully', async () => {
    const mockManifest = {
      version: '0.3.0',
      generatedAt: '2025-01-15T10:00:00Z',
      totalRecords: 100,
      totalSizeBytes: 1000000,
      shards: []
    }

    global.fetch = vi.fn().mockResolvedValue({
      ok: true,
      json: async () => mockManifest
    })

    const { fetchManifest } = useShardLoader()
    const result = await fetchManifest()

    expect(result).toEqual(mockManifest)
  })

  it('should detect changed shards', async () => {
    // Test implementation
  })

  it('should validate checksums correctly', async () => {
    const { validateChecksum } = useShardLoader()

    const content = 'test content'
    const validChecksum = 'expected-sha256-hash'

    // Mock crypto.subtle.digest
    // Test validation logic
  })

  it('should parse NDJSON correctly', () => {
    const { parseNDJSON } = useShardLoader()

    const ndjson = `{"id":"1","name":"Food 1"}
{"id":"2","name":"Food 2"}
{"id":"3","name":"Food 3"}`

    const records = parseNDJSON(ndjson)

    expect(records).toHaveLength(3)
    expect(records[0].id).toBe('1')
  })

  it('should handle malformed NDJSON gracefully', () => {
    const { parseNDJSON } = useShardLoader()

    const malformed = `{"id":"1","name":"Food 1"}
{invalid json}
{"id":"3","name":"Food 3"}`

    expect(() => parseNDJSON(malformed)).toThrow()
  })

  it('should track download progress', async () => {
    // Test progress tracking during download
  })

  it('should handle quota exceeded errors', async () => {
    // Mock QuotaExceededError
    // Test error handling
  })
})
```

**File**: `src/composables/__tests__/useStorageQuota.spec.ts`

```typescript
import { describe, it, expect, beforeEach, vi } from 'vitest'
import { useStorageQuota } from '../useStorageQuota'

describe('useStorageQuota', () => {
  beforeEach(() => {
    // Mock navigator.storage.estimate
    global.navigator.storage = {
      estimate: vi.fn()
    } as any
  })

  it('should fetch storage quota info', async () => {
    vi.mocked(navigator.storage.estimate).mockResolvedValue({
      quota: 10000000,
      usage: 5000000
    })

    const { quotaInfo, updateQuotaInfo } = useStorageQuota()
    await updateQuotaInfo()

    expect(quotaInfo.value).toEqual({
      quota: 10000000,
      usage: 5000000,
      available: 5000000,
      percentUsed: 50
    })
  })

  it('should detect low storage', async () => {
    vi.mocked(navigator.storage.estimate).mockResolvedValue({
      quota: 10000000,
      usage: 8500000
    })

    const { isLowStorage, updateQuotaInfo } = useStorageQuota()
    await updateQuotaInfo()

    expect(isLowStorage.value).toBe(true)
  })

  it('should detect critical storage', async () => {
    vi.mocked(navigator.storage.estimate).mockResolvedValue({
      quota: 10000000,
      usage: 9500000
    })

    const { isCriticalStorage, updateQuotaInfo } = useStorageQuota()
    await updateQuotaInfo()

    expect(isCriticalStorage.value).toBe(true)
  })

  it('should check available space', async () => {
    vi.mocked(navigator.storage.estimate).mockResolvedValue({
      quota: 10000000,
      usage: 7000000
    })

    const { checkAvailableSpace } = useStorageQuota()

    const sufficient = await checkAvailableSpace(2000000)
    expect(sufficient).toBe(true)

    const insufficient = await checkAvailableSpace(5000000)
    expect(insufficient).toBe(false)
  })
})
```

**File**: `src/composables/__tests__/useIndexedDB.spec.ts` (additions)

```typescript
// Add to existing useIndexedDB tests

describe('useIndexedDB - v0.3 additions', () => {
  it('should save shard metadata', async () => {
    const { saveShardMetadata, getShardMetadata } = useIndexedDB()

    const metadata = {
      id: 'shard-001',
      filename: 'nutrients-001.ndjson',
      checksum: 'abc123',
      loadedAt: Date.now(),
      recordCount: 100,
      status: 'loaded' as const
    }

    await saveShardMetadata(metadata)
    const retrieved = await getShardMetadata('shard-001')

    expect(retrieved).toEqual(metadata)
  })

  it('should save manifest version', async () => {
    const { saveManifestVersion, getManifestVersion } = useIndexedDB()

    const version = {
      id: 'current' as const,
      version: '0.3.0',
      updatedAt: Date.now(),
      totalRecords: 7125,
      loadedShards: 5
    }

    await saveManifestVersion(version)
    const retrieved = await getManifestVersion()

    expect(retrieved).toEqual(version)
  })

  it('should import records atomically', async () => {
    const { importNutrientRecords } = useIndexedDB()

    const records = [
      { id: '1', FoodDescription: 'Food 1', /* ... */ },
      { id: '2', FoodDescription: 'Food 2', /* ... */ }
    ]

    await importNutrientRecords(records)

    // Verify records were imported
    // Test transaction atomicity
  })

  it('should rollback on import error', async () => {
    const { importNutrientRecords } = useIndexedDB()

    const invalidRecords = [
      { id: '1', FoodDescription: 'Food 1' },
      null,  // Invalid record
      { id: '3', FoodDescription: 'Food 3' }
    ]

    await expect(importNutrientRecords(invalidRecords as any)).rejects.toThrow()

    // Verify no records were imported (atomic rollback)
  })
})
```

### Integration Tests

**File**: `src/components/__tests__/shard-loading-integration.spec.ts`

```typescript
import { describe, it, expect, beforeEach } from 'vitest'
import { mount } from '@vue/test-utils'
import { createPinia, setActivePinia } from 'pinia'
import App from '@/App.vue'

describe('Shard Loading Integration', () => {
  beforeEach(() => {
    setActivePinia(createPinia())
  })

  it('should complete full dataset update workflow', async () => {
    // 1. Mock manifest fetch
    // 2. Mock shard downloads
    // 3. Verify IndexedDB updates
    // 4. Verify UI progress updates
    // 5. Verify search works after import
  })

  it('should handle network interruption and resume', async () => {
    // 1. Start dataset download
    // 2. Simulate network failure mid-download
    // 3. Verify partial state saved
    // 4. Resume download
    // 5. Verify completion
  })

  it('should detect and download only changed shards', async () => {
    // 1. Load initial dataset
    // 2. Mock manifest with 1 changed shard
    // 3. Verify only changed shard downloaded
    // 4. Verify data integrity
  })

  it('should handle quota exceeded error gracefully', async () => {
    // 1. Mock low storage quota
    // 2. Attempt dataset download
    // 3. Verify error displayed
    // 4. Verify cleanup options offered
  })
})
```

### E2E Tests

**File**: `e2e/shard-loading.spec.ts`

```typescript
import { test, expect } from '@playwright/test'

test.describe('Shard Loading', () => {
  test('should display progress during dataset download', async ({ page }) => {
    await page.goto('/')

    // Wait for dataset update to start
    await page.waitForSelector('.dataset-update-progress')

    // Verify progress bar visible
    const progressBar = page.locator('.progress-bar')
    await expect(progressBar).toBeVisible()

    // Wait for completion
    await page.waitForSelector('.text-success', { timeout: 60000 })

    // Verify dataset is searchable
    await page.goto('/carb-factor')
    const searchInput = page.locator('input[type="search"]').first()
    await searchInput.fill('cheese')

    await expect(page.locator('.search-results')).toBeVisible()
  })

  test('should work offline after dataset loaded', async ({ page, context }) => {
    // Load dataset
    await page.goto('/')
    await page.waitForLoadState('networkidle')

    // Wait for dataset to load
    await page.waitForSelector('[data-dataset-loaded="true"]', { timeout: 60000 })

    // Go offline
    await context.setOffline(true)

    // Verify search works
    await page.goto('/carb-factor')
    const searchInput = page.locator('input[type="search"]').first()
    await searchInput.fill('milk')

    await expect(page.locator('.search-results')).toBeVisible()
  })

  test('should show storage quota in settings', async ({ page }) => {
    await page.goto('/settings')

    const storageQuota = page.locator('.storage-quota')
    await expect(storageQuota).toBeVisible()

    // Verify progress bar
    await expect(storageQuota.locator('.progress')).toBeVisible()

    // Verify percentage displayed
    const progressText = await storageQuota.locator('.progress-bar').textContent()
    expect(progressText).toMatch(/\d+%/)
  })
})
```

## Deployment

### Build Process

Production build (`npm run build`) now includes:

1. **ETL Pipeline Execution**:
   - `npm run generate-shards` runs automatically via `prebuild` script
   - Splits dataset into NDJSON shards
   - Generates `manifest.json` with checksums
   - Outputs to `public/data/` directory

2. **Static Assets**:
   - Shards copied to `dist/data/`
   - Manifest copied to `dist/data/manifest.json`
   - All files served as static assets via GitHub Pages

3. **Bundle Optimization**:
   - Enhanced tree-shaking for new composables
   - Code splitting for shard loader
   - Service Worker updated to cache manifest

### Deployment Checklist

- [ ] Run `npm run build` successfully
- [ ] Verify `dist/data/manifest.json` exists and is valid JSON
- [ ] Verify all shard files exist in `dist/data/`
- [ ] Check manifest checksums match shard files
- [ ] Run `npm run preview` and test dataset loading locally
- [ ] Verify storage quota display in settings
- [ ] Test dataset update with simulated manifest change
- [ ] Verify offline functionality after dataset loaded
- [ ] Test on low-storage device (< 100 MB available)
- [ ] Check Service Worker registration includes new files

### Deployment to GitHub Pages

```bash
# Build with shard generation
npm run build

# Deploy to GitHub Pages
npm run deploy  # or manual gh-pages deployment

# Verify deployment
# 1. Check manifest URL: https://yourusername.github.io/gluko/data/manifest.json
# 2. Check shard URLs: https://yourusername.github.io/gluko/data/nutrients-001.ndjson
# 3. Test app loads and fetches dataset
```

### Rollback Plan

If issues occur:

1. **Revert code changes**:
   - Revert commit and redeploy
   - Service Worker cache busting happens automatically

2. **Manifest rollback**:
   - Deploy previous version of manifest.json
   - Clients will detect version change and re-download

3. **Data integrity**:
   - User meal history in IndexedDB unaffected
   - Shard metadata can be cleared and reloaded

4. **Emergency fix**:
   - Deploy single-file dataset as fallback
   - Update code to check for manifest.json existence
   - Fall back to v0.1 loading mechanism if manifest missing

## Monitoring

### Performance Metrics

**New Metrics for v0.3**:

- **Dataset Load Time**: Time from manifest fetch to first search ready
  - Target: < 30 seconds on 3G connection
  - Measure: Performance marks in shard loader

- **Incremental Update Time**: Time to download and import changed shards only
  - Target: < 10 seconds for single shard update
  - Measure: Progress tracking logs

- **Storage Efficiency**: Dataset size vs IndexedDB usage
  - Target: < 20 MB for full dataset in IndexedDB
  - Measure: Storage API usage after import

- **Resumability Success Rate**: Percentage of interrupted downloads that resume successfully
  - Target: > 95%
  - Measure: Error tracking in shard metadata

### Error Tracking

**Critical Paths to Monitor**:

1. **Manifest Fetch Failures**:
   - Network errors
   - Parse errors (invalid JSON)
   - Version mismatch errors

2. **Shard Download Failures**:
   - Network interruptions
   - 404 errors (missing shards)
   - Timeout errors

3. **Checksum Validation Failures**:
   - Corrupted downloads
   - Mismatched checksums
   - Retry mechanism effectiveness

4. **IndexedDB Import Errors**:
   - QuotaExceededError frequency
   - Transaction failures
   - Atomic rollback success rate

5. **Storage Quota Issues**:
   - Percentage of users hitting storage limits
   - Cleanup action effectiveness
   - Partial dataset usage patterns

### Success Criteria

From release document:

- [x] Manifest file generated correctly by ETL with all shards listed
- [x] App downloads all shards on first run
- [x] Shard checksums validated before storage
- [ ] On unchanged manifest, zero downloads on repeat visits (use cached data)
- [ ] On manifest change, only changed shards downloaded
- [ ] Dataset fully searchable after import
- [ ] Interrupted download can resume from last checkpoint
- [ ] Works on low-end devices (< 4 GB RAM)

### Implementation Status

**Completed**:

- ETL pipeline for shard generation
- Manifest format and schema
- Shard loader composable with progress tracking
- IndexedDB schema updates (v3)
- Storage quota management
- UI components for progress and quota display
- Checksum validation with SubtleCrypto API
- Atomic import transactions
- Unit and integration test structure

**In Progress**:

- E2E tests for full workflow
- Error recovery UI refinements
- Performance optimization for large shards

**Not Started**:

- Cleanup storage implementation
- Advanced resumability (per-shard checkpoint)
- Compression investigation for v0.4

## Known Limitations

### GitHub Pages Constraints

- **No Compression**: Shards served uncompressed (2-3 MB each)
  - Future: Move to CDN with automatic gzip/brotli
  - Future: Implement client-side decompression

- **No Range Requests**: Cannot resume partial shard downloads
  - Workaround: Download complete shards only
  - Future: Server-side range request support

### Storage Constraints

- **Mobile Devices**: Some devices may have < 50 MB available
  - Mitigation: Pre-check quota before download
  - Future: Partial dataset option (core foods only)

- **IndexedDB Limits**: Browser-specific quota limits vary
  - Chrome: ~60% of available disk space
  - Firefox: ~50% of available disk space
  - Safari: ~1 GB persistent, ~50 MB temporary

### Performance Variability

- **Network Speed**: 3G download times can exceed 60 seconds
  - Progress indicator provides feedback
  - Resumability reduces retry frustration

- **Device Performance**: Low-end devices may struggle with large NDJSON parsing
  - Target: Keep shards < 3 MB uncompressed
  - Future: Web Worker parsing for non-blocking

## What v0.3 Enables

With v0.3 complete, the app now has:

1. **Efficient Dataset Updates**: Only download changed data (incremental updates)
2. **Mobile-Friendly Loading**: Split large dataset into manageable chunks
3. **Resumable Downloads**: Handle network interruptions gracefully
4. **Storage Awareness**: Proactive quota management and user feedback
5. **Production-Ready Data Pipeline**: Automated ETL for dataset versioning

This provides foundation for:

- **v0.4**: Service Worker optimization, caching strategies, Web Worker parsing
- **v0.5**: UI polish, advanced search features, favorites sync
- **v0.6**: Data export/import, backup functionality
- **v1.0**: Production release with comprehensive dataset management

## Related Documentation

- **Current release**: [v0.3-shard-loading.md](../releases/v0.3-shard-loading.md)
- **Previous implementation**: [v0.2-pwa-installability.md](v0.2-pwa-installability.md)
- **Release tracker**: [RELEASE_TRACKER.md](../releases/RELEASE_TRACKER.md)
- **Next release**: [v0.4-pwa-optimization.md](../releases/v0.4-pwa-optimization.md)
- Product goals: [PRODUCT.md](../PRODUCT.md)
- Architecture: [ARCHITECTURE.md](../ARCHITECTURE.md)
