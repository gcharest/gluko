# Release v0.2: PWA Installability & Quality Gates

## Release Summary

Complete the PWA implementation by adding manifest.json and app icons, establish automated quality gates with comprehensive test coverage, and validate performance targets to ensure production-readiness foundation.

## Goals

1. **PWA installability**: Enable "Add to Home Screen" on iOS and Android with proper manifest and icons
2. **Offline validation**: Test and document full offline functionality end-to-end
3. **Test coverage**: Achieve 80%+ coverage on all Pinia stores and composables
4. **Performance monitoring**: Add Lighthouse CI to automatically validate Web Vitals targets
5. **Quality gates**: Establish automated pass/fail criteria for commits and PRs

## Constraints Specific to This Release

- **vite-plugin-pwa already installed**: Build on existing Service Worker registration
- **No data model changes**: Focus on PWA metadata and testing, not schema changes
- **Target browsers**: iOS 15+, Android Chrome 90+
- **Performance baseline**: Must establish measurements before optimization
- **CI environment**: Use GitHub Actions free tier

## Options Considered

### Option A: PWA only (skip testing improvements)

- **Approach**: Add manifest.json and icons, skip test coverage improvements
- **Pros**: Quick path to installability
- **Cons**: No confidence for v1.0 without tests, can't detect regressions
- **Risk**: Medium (works but risky for production)

### Option B: Testing only (defer PWA completion)

- **Approach**: Focus on test coverage, skip manifest/icons
- **Pros**: Strong quality foundation
- **Cons**: App still not installable, delays key product feature
- **Risk**: Low but doesn't advance product vision

### Option C: PWA + Testing + Performance Monitoring (Comprehensive)

- **Approach**: Complete PWA implementation, establish test coverage, add Lighthouse CI
- **Pros**: Both installability AND quality confidence, ready for v0.3+
- **Cons**: More work upfront
- **Risk**: Low (essential for v1.0 readiness)

## Selected: Option C

**Why**: Both PWA completion and testing are blockers for v1.0. Doing them together establishes a strong foundation for subsequent releases. Performance monitoring prevents regressions as we add features.

## Success Criteria

### PWA Installability

- [ ] `manifest.json` created with complete metadata:
  - App name, short name, description (EN/FR)
  - Start URL, scope, display mode (standalone)
  - Theme color, background color
  - Icon references (all sizes and purposes)
  - Categories (medical, health, food)
- [ ] Icon set generated and included:
  - 192x192 PNG (standard)
  - 512x512 PNG (high-res)
  - Maskable icon variants (safe zone respected)
  - Favicon updated
- [ ] PWA installability validated:
  - "Add to Home Screen" works on iOS Safari
  - "Add to Home Screen" works on Android Chrome
  - Custom app name appears on home screen
  - App launches in standalone/fullscreen mode
  - No browser UI chrome visible when installed
- [ ] Lighthouse PWA audit score ≥ 90

### Offline Functionality

- [ ] Complete offline validation:
  - App loads offline after initial install
  - Can search nutrients offline
  - Can calculate meals offline
  - Can view/add to history offline
  - Can manage subjects offline
- [ ] Service Worker lifecycle tested:
  - Update prompt shows when new version available
  - User can refresh to get latest version
  - No errors during SW update
- [ ] Offline error handling:
  - Clear messaging when features require network (none should)
  - No console errors in offline mode

### Test Coverage

- [ ] Unit tests for all Pinia stores (80%+ coverage):
  - `nutrientsFile.ts`: search, favorites, data loading
  - `meal.ts`: meal calculations, item management
  - `mealHistory.ts`: add, update, delete, filtering
  - `subject.ts`: create, switch, manage subjects
  - `session.ts`: session handling
- [ ] Unit tests for composables (80%+ coverage):
  - `useIndexedDB.ts`: CRUD operations, error handling, date serialization, index queries
- [ ] Integration tests:
  - Multi-store workflows (add meal → save to history → retrieve)
  - IndexedDB transaction handling
  - Data persistence across store resets
- [ ] Coverage reporting:
  - HTML coverage report generated locally
  - Coverage summary in PR comments
  - Coverage badges in README.md (optional)

### Performance Monitoring

- [ ] Lighthouse CI configured in GitHub Actions
- [ ] Performance thresholds enforced:
  - LCP < 2.5s (assertion in CI)
  - FCP < 1.8s (assertion in CI)
  - TBT < 200ms (assertion in CI)
  - PWA score ≥ 90
  - Accessibility score ≥ 95
- [ ] Bundle size monitoring:
  - Baseline bundle sizes documented
  - Alert on significant size increases (optional)
- [ ] Performance results visible:
  - Lighthouse reports in CI artifacts
  - Performance dashboard or tracking (optional)

### Documentation

- [ ] Implementation documentation:
  - Document v0.1 implementation (what's currently built)
  - Create v0.2 implementation doc (this release)
- [ ] Architecture alignment:
  - Update ARCHITECTURE.md to reflect current reality
  - Mark unimplemented features clearly (e.g., "⏳ Planned: Dataset sharding")
- [ ] Testing guide:
  - Document how to run tests locally
  - Document coverage requirements
  - Document how to add new tests

## Implementation Plan

### Phase 1: PWA Manifest & Icons

1. Create `public/manifest.json`:
   - Use vite-plugin-pwa to generate or create manually
   - Include all required fields
   - Support both EN/FR (or use EN with proper i18n strategy)

2. Generate PWA icons:
   - Use online tool (e.g., PWA Asset Generator, RealFaviconGenerator)
   - Or create manually with design tool
   - Include all required sizes and purposes

3. Update `vite.config.ts`:
   - Configure vite-plugin-pwa to include manifest
   - Ensure icons are copied to build output

4. Test installability:
   - iOS Safari (iPhone)
   - Android Chrome (Android device or emulator)
   - Validate with Lighthouse PWA audit

### Phase 2: Offline Validation

1. Create E2E test for offline functionality:
   - Add Playwright test that simulates offline mode
   - Test all core features work without network

2. Manual testing checklist:
   - Install app on device
   - Enable airplane mode
   - Verify all features work
   - Document findings

3. Update documentation:
   - Document offline capabilities
   - Add troubleshooting guide for offline issues

### Phase 3: Unit Tests

1. Test `useIndexedDB` composable:
   - Mock IndexedDB (use happy-dom or fake-indexeddb)
   - Test all CRUD operations
   - Test error handling (quota, permission, etc.)
   - Test date serialization
   - Test index queries

2. Test all Pinia stores:
   - Use @pinia/testing for store testing
   - Test state mutations
   - Test actions
   - Test getters/computed properties
   - Test persistence (IndexedDB interactions)

3. Integration tests:
   - Test multi-store workflows
   - Test data flow between stores
   - Test IndexedDB schema interactions

### Phase 4: Performance Monitoring

1. Add Lighthouse CI:
   - Create `.github/workflows/lighthouse.yml`
   - Configure thresholds for LCP, FCP, TBT
   - Run on PRs and main branch

2. Document baseline performance:
   - Run Lighthouse locally on main branch
   - Record current metrics
   - Use as baseline for future improvements

3. Add bundle size tracking (optional):
   - Use `rollup-plugin-visualizer` or similar
   - Generate bundle analysis report
   - Document in PR artifacts

### Phase 5: Documentation

1. Create `docs/implementation/v0.1-mvp.md`:
   - Document what was built in v0.1
   - Architecture decisions
   - Implementation notes

2. Create `docs/implementation/v0.2-pwa-quality.md`:
   - Document this release implementation
   - PWA setup guide
   - Testing strategy

3. Update ARCHITECTURE.md:
   - Align with current state
   - Mark future features clearly
   - Update component structure diagram

## Known Risks

- **Icon design effort**: Creating custom icons requires design work → Use online generator or simple design
- **Testing complexity**: Mocking IndexedDB can be tricky → Use happy-dom (better IDB support) or fake-indexeddb
- **Lighthouse CI variability**: Performance scores can vary → Use median of 3 runs, accept small variance
- **Coverage target pressure**: 80% coverage takes time → Focus on critical paths first (stores, composables)
- **Browser testing**: Need real devices for iOS → Use BrowserStack or test on personal devices

## Out of Scope

- Dataset sharding and manifest versioning (v0.3)
- Web Workers for non-blocking imports (v0.4)
- Advanced UI polish and refinements (v0.5)
- History export/import (v0.6)
- Performance optimization work (that's v0.4; this is measurement only)

## What v0.2 Enables

With v0.2 complete, we will have:

1. **Installable PWA**: Users can add app to home screen (key product requirement)
2. **Confidence for v1.0**: Comprehensive tests prevent regressions
3. **Performance baseline**: Know where we stand, can track improvements
4. **Automated quality gates**: CI prevents quality regressions
5. **Documentation alignment**: Docs reflect reality, easier onboarding

This creates a solid foundation for v0.3 (dataset sharding) and beyond.

## Related Documentation

- **Current state**: [v0.1-mvp.md](v0.1-mvp.md)
- **Release tracker**: [RELEASE_TRACKER.md](RELEASE_TRACKER.md)
- **Next release**: [v0.3-shard-loading.md](v0.3-shard-loading.md)
- Product goals: [PRODUCT.md](../PRODUCT.md)
- Architecture: [ARCHITECTURE.md](../ARCHITECTURE.md)
- Project review: [PROJECT_REVIEW.md](../PROJECT_REVIEW.md)
